{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W rknn-toolkit-lite2 version: 2.3.2\n",
      "W rknn-toolkit-lite2 version: 2.3.2\n",
      "W Query dynamic range failed. Ret code: RKNN_ERR_MODEL_INVALID. (If it is a static shape RKNN model, please ignore the above warning message.)\n",
      "W Query dynamic range failed. Ret code: RKNN_ERR_MODEL_INVALID. (If it is a static shape RKNN model, please ignore the above warning message.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I RKNN: [19:18:25.320] RKNN Runtime Information, librknnrt version: 2.3.2 (429f97ae6b@2025-04-09T09:09:27)\n",
      "I RKNN: [19:18:25.322] RKNN Driver Information, version: 0.9.8\n",
      "I RKNN: [19:18:25.325] RKNN Model Information, version: 6, toolkit version: 2.0.0b20+c40fb1c7(compiler version: 2.0.0b19 (215a5dcd6a@2024-06-25T06:36:46)), target: RKNPU v2, target platform: rk3588, framework name: ONNX, framework layout: NCHW, model inference type: static_shape\n",
      "W RKNN: [19:18:25.417] query RKNN_QUERY_INPUT_DYNAMIC_RANGE error, rknn model is static shape type, please export rknn with dynamic_shapes\n",
      "I RKNN: [19:18:25.509] RKNN Runtime Information, librknnrt version: 2.3.2 (429f97ae6b@2025-04-09T09:09:27)\n",
      "I RKNN: [19:18:25.509] RKNN Driver Information, version: 0.9.8\n",
      "I RKNN: [19:18:25.509] RKNN Model Information, version: 6, toolkit version: 2.0.0b20+c40fb1c7(compiler version: 2.0.0b19 (215a5dcd6a@2024-06-25T06:36:46)), target: RKNPU v2, target platform: rk3588, framework name: ONNX, framework layout: NCHW, model inference type: static_shape\n",
      "W RKNN: [19:18:25.516] query RKNN_QUERY_INPUT_DYNAMIC_RANGE error, rknn model is static shape type, please export rknn with dynamic_shapes\n",
      "get time : 45.71700096130371ms\n"
     ]
    }
   ],
   "source": [
    "import get_embedding\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "def cosine_similarity1(x, y):\n",
    "    return np.dot(x, y) / (np.sqrt(np.dot(x, x)) * np.sqrt(np.dot(y, y)))\n",
    "\n",
    "def extract_filename(file_path):\n",
    "    full_filename = os.path.basename(file_path)\n",
    "    filename_without_extension = os.path.splitext(full_filename)[0]\n",
    "    return filename_without_extension\n",
    "\n",
    "image4 = \"./img/xu_1.jpg\"\n",
    "#image4 = \"./face.jpg\"\n",
    "images = [ \"./img/select_sy2_face.jpg\", \"./img/select_sy2_face.jpg\", \"./img/lin_1.jpg\", \"./img/lin_2.jpg\", \"./img/lin_3.jpg\", \"./img/xu_2.jpg\", \"./img/xu_3.jpg\"]\n",
    "path=os.getcwd()\n",
    "\n",
    "get_embedding.init()\n",
    "img1 = cv2.imread(image4)\n",
    "start_time = time.time()\n",
    "get_face1 = get_embedding.get_embeddings(img1)\n",
    "feature1 = get_face1[0]['embedding']\n",
    "print( f'get time : {(time.time() - start_time)*1000}ms')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: select_sy2_face, match: [False], face_distances : 0.2693970799446106\n",
      "name: select_sy2_face, match: [False], face_distances : 0.2693970799446106\n",
      "name: lin_1, match: [False], face_distances : 0.41379281878471375\n",
      "name: lin_2, match: [False], face_distances : 0.41748934984207153\n",
      "name: lin_3, match: [False], face_distances : 0.4583040177822113\n",
      "name: xu_2, match: [ True], face_distances : 0.6512731313705444\n",
      "name: xu_3, match: [ True], face_distances : 0.7926830649375916\n",
      "Person name : xu_3\n"
     ]
    }
   ],
   "source": [
    "detect_list = []\n",
    "for j in range(len(images)):\n",
    "    img2 = cv2.imread(images[j])\n",
    "    start_time = time.time()\n",
    "    get_face2 = get_embedding.get_embeddings(img2)\n",
    "    personname = extract_filename(images[j])\n",
    "    for i in range(len(get_face2)):\n",
    "        feature2 = get_face2[i]['embedding']\n",
    "        #print( f'get time : {(time.time() - start_time)*1000}ms')\n",
    "        match, cosine_similarity = get_embedding.compare_face(feature1, feature2)\n",
    "        #cosine_similarity_1 = cosine_similarity1(feature1[0], feature2[0])\n",
    "        #print( f'name: {personname}, match: {match}, face_distances : {cosine_similarity[0]}, {cosine_similarity_1}'  )\n",
    "        print( f'name: {personname}, match: {match}, face_distances : {cosine_similarity[0]}'  )\n",
    "        if match == [True]:\n",
    "            detect_list.append([j,i,cosine_similarity[0] ])\n",
    "\n",
    "if len(detect_list)>0 :\n",
    "    max_value = max(detect_list, key=lambda x: x[2])[0]\n",
    "    file_path = images[max_value]\n",
    "    # Extract only the file name\n",
    "    personname = extract_filename(file_path)\n",
    "    print(\"Person name :\", personname)\n",
    "else:\n",
    "    print( \"Unkown!!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rknnlite",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
